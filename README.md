# URL Page Type Classifier

åŸºäº Qwen2.5-1.5B + LoRA çš„URLç±»å‹åˆ†ç±»æ¨¡å‹ï¼Œç”¨äºåˆ¤æ–­URLæ˜¯åˆ—è¡¨é¡µè¿˜æ˜¯è¯¦æƒ…é¡µã€‚

## åŠŸèƒ½

- åˆ¤æ–­URLæ˜¯åˆ—è¡¨é¡µ (List Page) è¿˜æ˜¯è¯¦æƒ…é¡µ (Detail Page)
- æ”¯æŒGPUå’ŒCPUæ¨ç†
- ä½¿ç”¨LoRAå¾®è°ƒï¼Œæ¨¡å‹è½»é‡

## ç¯å¢ƒè¦æ±‚

- Python 3.10+
- PyTorch 2.5+
- Transformers
- PEFT
- å»ºè®®: NVIDIA GPU (RTX 4060+)

## å®‰è£…

```bash
# åˆ›å»ºcondaç¯å¢ƒ
conda create -n url-classifier python=3.11
conda activate url-classifier

# å®‰è£…ä¾èµ–
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
pip install transformers peft datasets accelerate
```

## è®­ç»ƒ

### 1. å‡†å¤‡æ•°æ®

ä» HuggingFace ä¸‹è½½æ•°æ®é›†:

```python
from datasets import load_dataset
import json
import random

random.seed(42)

ds = load_dataset('IowaCat/page_type_inference_dataset')
train_data = ds['train']

# é‡‡æ ·
list_pages = [url for url, label in zip(train_data['url'], train_data['label']) if label == 0]
detail_pages = [url for url, label in zip(train_data['url'], train_data['label']) if label == 1]

sampled_list = random.sample(list_pages, 5000)
sampled_detail = random.sample(detail_pages, 5000)

# è½¬æ¢ä¸ºè®­ç»ƒæ ¼å¼
data = []
for url in sampled_list:
    data.append({
        "instruction": "è¯·åˆ¤æ–­ä»¥ä¸‹URLæ˜¯åˆ—è¡¨é¡µè¿˜æ˜¯è¯¦æƒ…é¡µã€‚",
        "input": url,
        "output": "åˆ—è¡¨é¡µ (List Page)"
    })
for url in sampled_detail:
    data.append({
        "instruction": "è¯·åˆ¤æ–­ä»¥ä¸‹URLæ˜¯åˆ—è¡¨é¡µè¿˜æ˜¯è¯¦æƒ…é¡µã€‚",
        "input": url,
        "output": "è¯¦æƒ…é¡µ (Detail Page)"
    })

random.shuffle(data)

with open('data/data.json', 'w', encoding='utf-8') as f:
    json.dump(data, f, ensure_ascii=False, indent=2)
```

### 2. è®­ç»ƒæ¨¡å‹

```bash
python src/train.py
```

è®­ç»ƒé…ç½®:
- æ¨¡å‹: Qwen2.5-1.5B
- LoRA rank: 16
- Epochs: 3
- Batch size: 2
- Gradient accumulation: 8
- Learning rate: 2e-4

## æ¨ç†

### GPUæ¨ç†

```bash
python src/infer.py "https://example.com/product/12345"
```

### CPUæ¨ç†

```bash
python src/infer.py "https://example.com/products/list" --cpu
```

## é¡¹ç›®ç»“æ„

```
url-classifier/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ data.json          # è®­ç»ƒæ•°æ®
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ train.py          # è®­ç»ƒè„šæœ¬
â”‚   â”œâ”€â”€ infer.py          # æ¨ç†è„šæœ¬
â”‚   â””â”€â”€ utils.py          # å·¥å…·å‡½æ•°
â”œâ”€â”€ output/                # æ¨¡å‹è¾“å‡ºç›®å½• (ä¸æäº¤)
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

## æµ‹è¯•ç»“æœ

| æµ‹è¯•é›† | å‡†ç¡®ç‡ |
|--------|--------|
| 100æ¡éªŒè¯é›† | 99% |

## æ¨¡å‹ä¸‹è½½

è®­ç»ƒå®Œæˆåï¼Œæ¨¡å‹ä¿å­˜åœ¨ `output/checkpoint-300/` ç›®å½•ã€‚

### ğŸ¤— HuggingFace æ¨¡å‹

æ¨¡å‹å·²ä¸Šä¼ è‡³ HuggingFaceï¼Œå¯ç›´æ¥ä¸‹è½½ä½¿ç”¨ï¼š

```bash
# æ–¹æ³•1: ä½¿ç”¨ git
git lfs install
git clone https://huggingface.co/windlx/url-classifier-model

# æ–¹æ³•2: ä½¿ç”¨ Python
from transformers import AutoModelForCausalLM
model = AutoModelForCausalLM.from_pretrained("windlx/url-classifier-model")
```

**HuggingFace æ¨¡å‹åœ°å€**: https://huggingface.co/windlx/url-classifier-model

```python
from transformers import AutoModelForCausalLM
from peft import PeftModel

base_model = AutoModelForCausalLM.from_pretrained('Qwen/Qwen2.5-1.5B')
model = PeftModel.from_pretrained(base_model, 'output/checkpoint-300')
model.merge_and_unload()
model.save_pretrained('output/merged-model')
```

## License

[MIT License](LICENSE)
